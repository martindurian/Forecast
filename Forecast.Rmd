---
title: "Energy consumption estimation"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, include = FALSE, warning = FALSE, message=FALSE)
```


## Data preparation

```{r Data preparation}
library(tidyverse)
library(tsibble)
library(lubridate)
# library(fpp3) #tsibbledata, feasts, fable
library(cowplot)
library(ggwrap)
library(fable)
library(fable.prophet)
library(fabletools)


working_path <- "C:/Users/sk0007/OneDrive - Daikin Europe N.V/Documents/R scripts/DCS/DCS/DM_all/DM PodBisk 01012018-31122019"
source("C:/Users/sk0007/OneDrive - Daikin Europe N.V/Documents/R scripts/DCS/DCS/MasterSctripts/Functions.R")
load(file=file.path(working_path, "Data_structure.Rda"))

# data frame preparation -----
outdoor_dframe <- Data_structure$Out_DF_list_outdoors[[1]] %>%
  mutate(OpeMode=if_else(Cooling.capacity==0&Heating.capacity==0&Operation.control.mode=="Heat recovery normal control", "HeRec", OpeMode)) %>% 
  select(TimeStampPosixct, consumption = Watt.hour.amount.Corrected., ambient = O.U.1.outside.air.temp., OpeMode, SystemIdentifier) %>% 
  mutate(consumption = replace(consumption, consumption == 0, 0.015))


sys_ident <- distinct(outdoor_dframe, SystemIdentifier) %>% 
  deframe()

# indoor average sepotints -----
indoors_average_values <- Data_structure %>% 
  pluck("Merged_Indoor_Units") %>%
  arrange(TimeStampPosixct) %>% 
  filter(SystemIdentifier == sys_ident) %>% 
  select(TimeStampPosixct, Avg..setting.temp., Indoor.unit.operation.time.accumulation, Suction.air.temp., UnitType, SystemIdentifier, UniqueIdentifier) %>% 
  mutate(Suction.air.temp. = replace(Suction.air.temp., Suction.air.temp. == 0, NA)) %>% 
  group_by(UniqueIdentifier) %>% 
  fill(Avg..setting.temp., Suction.air.temp., .direction = "downup") %>% 
  ungroup() %>% 
  mutate(unit_size = get_unit_size(UnitType), 
         setpoint_factor = Avg..setting.temp.*unit_size, 
         ope_time_factor = Indoor.unit.operation.time.accumulation/60 * unit_size,
         suction_factor = Suction.air.temp. * unit_size) %>% 
  group_by(TimeStampPosixct) %>% 
  summarise(setpoint_factor_sum = sum(setpoint_factor, na.rm = TRUE), 
            unit_size_sum = sum(unit_size, na.rm = TRUE), 
            average_setpoint=setpoint_factor_sum/unit_size_sum,
            ope_time_factor_sum = sum(ope_time_factor, na.rm = TRUE), 
            average_ope_time = ope_time_factor_sum/unit_size_sum, 
            suction_factor_sum = sum(suction_factor, na.rm = TRUE),
            average_suction = suction_factor_sum/unit_size_sum) %>% 
  ungroup() %>% 
  select(-contains("sum"))
  

# data frAme with indoor average setpoints -----
total_tsbl <- outdoor_dframe %>% 
  left_join(indoors_average_values, by="TimeStampPosixct") %>% 
  group_by(TimeStampPosixct) %>% 
  filter(row_number()==1) %>% 
  ungroup() %>% 
  as_tsibble(index = TimeStampPosixct) %>% 
  fill_gaps() %>% 
  fill(everything(), .direction = "downup")

# add dummy variables -----
add_dummy_fun <- function (df) df %>% 
  mutate(dummy.cooling = if_else(OpeMode == "Cooling", 1, 0),
         dummy.heating = if_else(OpeMode == "Heating", 1, 0),
         dummy.worktime = if_else(average_ope_time == 0, 0, 1))

tsbl_to_daily <- function (df) {
  daily_df <- df %>% 
  index_by(date.stamp = date(TimeStampPosixct)) %>% 
  summarise(OpeMode = names(table(OpeMode))[which.max(table(OpeMode))], 
            consumption = sum(consumption), 
            average_setpoint = mean(average_setpoint), 
            ambient = mean(ambient),
            average_ope_time = sum(average_ope_time, na.rm = TRUE),
            average_suction = mean(average_suction)) %>% 
            rename(TimeStampPosixct = date.stamp)
  return (daily_df)
}

hourly_tsbl <- total_tsbl %>% 
  add_dummy_fun() %>% 
  select(-c(OpeMode, SystemIdentifier))

daily_tsbl <- total_tsbl %>% 
  tsbl_to_daily() %>% 
  add_dummy_fun()%>% 
  select(-c(OpeMode))

data_lst <- list(daily_tsbl, hourly_tsbl) %>% 
  set_names(c("daily", "hourly"))

```

This is hourly and daily dataframe

```{r dataframes printout, include=TRUE}

hourly_tsbl %>% 
head(10) %>% 
flextable::flextable()

daily_tsbl %>% 
  head(10) %>% 
flextable::flextable()

write_csv(as_tibble(hourly_tsbl), path = file.path("C:/Users/sk0007/OneDrive - Daikin Europe N.V/Documents/R scripts/Forecast/Processing/hourly_tsbl.csv") )
write_csv(as_tibble(daily_tsbl), path = file.path("C:/Users/sk0007/OneDrive - Daikin Europe N.V/Documents/R scripts/Forecast/Processing/daily_tsbl.csv") )

```

## Evaluating predictors

Try to find predictors
Correlation matrix

```{r Correlation matrix, include=TRUE}
hourly_tsbl %>%
  as_tibble() %>%
  # select(consumption, ambient, average_suction, dummy.cooling, dummy.heating) %>%
  filter(dummy.heating == 1, consumption > 0) %>%
  select(-TimeStampPosixct,-contains("dummy")) %>%
GGally::ggpairs()
```

```{r evaluating predictors}

library(leaps)
# regsubsets.out <-
#     regsubsets(consumption ~ ambient + average_suction + average_setpoint + dummy.cooling + dummy.heating + dummy.cooling:average_setpoint + dummy.heating:average_setpoint + dummy.worktime,
#                data = hourly_tsbl,
#                nbest = 1,       # 1 best model for each number of predictors
#                nvmax = NULL,    # NULL for no limit on number of variables
#                force.in = NULL, force.out = NULL,
#                method = "exhaustive")
# regsubsets.out
# summary.out <- summary(regsubsets.out)
# as.data.frame(summary.out$outmat)
# plot(regsubsets.out, scale = "adjr2", main = "Adjusted R^2")
# 
# hourly df
regsubsets(consumption ~ ambient + average_setpoint + average_suction + dummy.cooling + dummy.heating + dummy.cooling:average_setpoint + dummy.heating:average_setpoint + dummy.worktime,
               data = hourly_tsbl,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive") %>% 
  plot(scale = "adjr2", main = "Adjusted R^2")

# daily df
regsubsets(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating + dummy.cooling:average_setpoint + dummy.heating:average_setpoint + dummy.worktime,
               data = daily_tsbl,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               force.in = NULL, force.out = NULL,
               method = "exhaustive") %>% 
  plot(scale = "adjr2", main = "Adjusted R^2")

```

## Models evaluation daily fit

Accuracy of the models
https://otexts.com/fpp3/accuracy.html

Selection of the predictors
https://otexts.com/fpp3/selecting-predictors.html

```{r better workflow daily fit, include=TRUE}
fit_model_fun <- function(tsbl) {
# training set
    sample_split <- rsample::initial_time_split(tsbl, prop = 3/4)
training_set <- rsample::training(sample_split)
# testing set
testing_set <- rsample::testing(sample_split)

# single fit multiple models
model_fit <- training_set %>% 
  model (Naive = NAIVE(consumption),
    TSLM_max = TSLM(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating + dummy.worktime + dummy.cooling:average_setpoint + dummy.heating:average_setpoint),
         TSLM_amb_set_dc = TSLM(consumption ~ ambient + average_setpoint + dummy.cooling),
         TSLM_amb_set_dc_dh = TSLM(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating),
         # TSLM_log_amb_set_dc_dh = TSLM(box_cox(consumption, lambda = 0) ~ ambient + average_setpoint + dummy.cooling + dummy.heating),
         AR_amb_set_dc_dh = ARIMA(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating),
         # AR_log_amb_set_dc_dh = ARIMA(box_cox(consumption, lambda = 0) ~ ambient + average_setpoint + dummy.cooling + dummy.heating),
         AR_amb_set_dc_dh_interfer = ARIMA(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating + dummy.worktime + dummy.cooling:average_setpoint + dummy.heating:average_setpoint),
         prophet = prophet(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating + dummy.worktime)
         )
return(list(model_fit = model_fit,
            training_set = training_set,
            testing_set = testing_set))
}

cat("Models:
time series linear models:
TSLM_max = 
TSLM(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating + dummy.worktime + dummy.cooling:average_setpoint + dummy.heating:average_setpoint)
TSLM_amb_set_dc = 
TSLM(consumption ~ ambient + average_setpoint + dummy.cooling)
TSLM_amb_set_dc_dh = 
TSLM(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating)
ARIMA models with regressors:
AR_amb_set_dc_dh =
ARIMA(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating)
AR_amb_set_dc_dh_interfer = 
ARIMA(consumption ~ ambient + average_setpoint + dummy.cooling + dummy.heating + dummy.worktime + dummy.cooling:average_setpoint + dummy.heating:average_setpoint\n")

fit_from <- "data"
switch (fit_from, 
        "data" = {
          daily_fit_lst <- fit_model_fun(daily_tsbl)
          hourly_fit <- fit_model_fun(hourly_tsbl)
          save(daily_fit_lst, file="daily_fit_lst.Rda")
          save(hourly_fit_lst, file="hourly_fit_lst.Rda")},
        "file" = {
          load(file="daily_fit_lst.Rda")
          load(file="hourly_fit_lst.Rda")
        })


daily_fit <- daily_fit_lst$model_fit
hourly_fit <- hourly_fit_lst$model_fit

testing_dfs_lst <- list(daily_fit_lst$testing_set, hourly_fit_lst$testing_set) %>% 
  set_names(c("daily", "hourly"))

training_dfs_lst <- list(daily_fit_lst$training_set, hourly_fit_lst$training_set) %>% 
  set_names(c("daily", "hourly"))

model_fits_lst <- list(daily_fit, hourly_fit) %>% 
  set_names(c("daily", "hourly"))


accuracies_lst <- map(model_fits_lst, function (model_fit) accuracy(model_fit))
cat("Accuracy of the models\n")
walk(accuracies_lst, ~print(flextable::flextable(.x)))

predictors_lst <- map(model_fits_lst, ~glance(.x))
cat("Predictors selection\n")
walk(predictors_lst, ~print(flextable::flextable(.x)))

best_mase_model_lst <- map(model_fits_lst, ~accuracy(.x) %>% 
  top_n(1, desc(MASE)) %>% 
  pull(.model))
  

```

## Summary of the consumption

```{r test the summed values, include=TRUE, fig.width=8, fig.height=15}
create_plot_fun <- function (model_df, real_cons_df, best_mase_model=NULL) {

if(".fitted" %in% names(model_df)) {
  y_var <- quo(.fitted)
  # real_cons_df <- quo(df)
}  else {
  y_var <- quo(consumption)
  # real_cons_df <- quo(testing_df)
}
  
panel_nr_fitted <- real_cons_df %>% 
    distinct(TimeStampPosixct) %>% 
    group_by(yearmonth(TimeStampPosixct)) %>% 
    count() %>% 
    nrow()

y_limit_fitted <- max(real_cons_df$consumption)*1.1



whole_plot_fitted_models <- model_df %>% 
  ggplot(aes(x = TimeStampPosixct, y = !!y_var, color = .model, shape = .model, size = .model == best_mase_model, group = .model))+
    geom_line() + 
    geom_point() + 
    scale_x_date(date_breaks = "1 day", date_labels = "%d", expand = c(0,0)) +
    scale_y_continuous(limits = c(0, y_limit_fitted)) +
    scale_size_manual(values = c(0.2, 1.5))+
    theme(axis.title = element_blank(), legend.position="bottom", panel.background = element_blank()) 

whole_plot_fitted <-  whole_plot_fitted_models +  
    geom_ribbon(data=real_cons_df, aes(x = TimeStampPosixct, ymin = 0, ymax = consumption), color = "black", fill = "grey 78", alpha = 0.4, size = 1, inherit.aes = F)
    

strip_plt <- ggwrap(whole_plot_fitted, panel_nr_fitted)
return(strip_plt)
}

fitted_dfs_lst <- map(model_fits_lst, ~ augment(.x))

undebug(create_plot_fun)
daily_plot <- create_plot_fun(model_df = fitted_dfs_lst$daily, 
                              real_cons_df = daily_fit_lst$training_set,
                              best_mase_model = best_mase_model_lst$daily)

fit_summaries_lst <- map(fitted_dfs_lst, ~.x %>% 
                           as_tibble() %>% 
                           group_by(.model) %>% 
                           summarise(sum(.fitted), sum(consumption)))

forecast_tsbl_lst <- map2(model_fits_lst, training_dfs_lst, ~forecast(select(.x, -prophet), new_data = .y))

cat("accuracy of the forecast\n")
fcst_accuracies_lst <- map2(forecast_tsbl_lst, data_lst, ~accuracy(.x, data = .y))
walk(fcst_accuracies_lst, ~print(flextable::flextable(.x)))

cat("summary of the forecasts - testing set\n")
fcst_summaries_lst <- map2(forecast_tsbl_lst, data_lst, ~.x %>% 
  as_tibble() %>% 
  group_by(.model) %>% 
  left_join (select(.y, real.consumption = consumption), by = "TimeStampPosixct") %>% 
  summarise(sum(real.consumption), sum(consumption), mean(real.consumption))
)

# forecast
cat("summary of the forecasts with setback = 2K\n")
fcst_setback_summaries <- map(list(daily_fit_lst, hourly_fit_lst), function(fit) {
  setback <- 2
testing_set_setback_tsbl <- fit$testing_set %>% 
  mutate(average_setpoint = case_when(dummy.cooling == 1 ~ average_setpoint+setback,
                                      dummy.heating == 1 ~ average_setpoint-setback,
                                      TRUE ~ average_setpoint))

forecast_daily_setback_tsbl <- forecast(select(fit$model_fit, -prophet) , new_data = testing_set_setback_tsbl)

forecast_daily_setback_tsbl %>% 
  as_tibble() %>% 
  group_by(.model) %>% 
  left_join (select(fit$testing_set, real.consumption = consumption), by = "TimeStampPosixct") %>% 
  summarise(sum(real.consumption), sum(consumption))
})

```


## Model forecast vs testing set

```{r ggwrap, include = T, fig.width=8, fig.height=30}
whole_plt <- forecast_daily_tsbl %>% 
  filter(str_detect(.model, "AR_")) %>% 
autoplot() + 
  autolayer(training_set_tsbl, color = "black") + 
  autolayer(select(testing_set_tsbl, real.consumption), color = "blue", size = 1) +
  theme_minimal_hgrid()+
  theme(legend.position = "bottom") +
  scale_x_date(date_breaks = "1 day", date_labels = "%d")

  # scale_color_manual(values = c("real.consumption" = "black"))
  # ggwrap(whole_plt, 6)
  
panel_nr <- daily_tsbl %>% 
    distinct(TimeStampPosixct) %>% 
    group_by(yearmonth(TimeStampPosixct)) %>% 
    count() %>% 
    nrow()

y_limit <- max(daily_tsbl$consumption)*1.1
    
whole_plt_2 <- ggplot(data = forecast_daily_tsbl, aes(x = TimeStampPosixct, y = consumption, color = .model, shape = .model, group = .model, size = .model == best_mase_model))+
    geom_line() + 
    geom_point() + 
    geom_ribbon(data = forecast_daily_tsbl, aes(x = TimeStampPosixct, ymin = 0, ymax = real.consumption), color = "black", fill = "grey 78", alpha = 0.4, size = 1, inherit.aes = F) +
    # geom_line (data = fitted_df) +
    scale_x_date(date_breaks = "1 day", date_labels = "%d", expand = c(0,0)) +
    scale_y_continuous(limits = c(0, y_limit))+
  scale_size_manual(values = c(0.2, 1.5))+
    theme(axis.title = element_blank(), legend.position="bottom", panel.background = element_blank())


  ggwrap(whole_plt_2, panel_nr)

```



 
```{r dygraphs nefunguje}
# library(tydygraphs)
# great_lakes_hydro %>% 
#   filter(lake == "Superior") %>% 
#   dygraph(water_level_m)
# 
# tsbl_to_convert <- daily_fit_lst$training_set %>% 
#   filter(yearmonth(TimeStampPosixct) == yearmonth(ymd("2018-05-15"))) %>%  
#   select(TimeStampPosixct, consumption)
# xts_tsbl <- tsbox::ts_xts(tsbl_to_convert)
# 
# xt_df <- xts(tsbl_to_convert, order.by = tsbl_to_convert$TimeStampPosixct)
# 
# daily_fit_lst$training_set %>% 
#   as_tibble() %>% 
# dygraph()
# 
# dygraph(xts_tsbl)
#  
#   dySeries("consumption", label = "consumption") %>%
#   dySeries("average_setpoint", label = "setpoint") %>%
#   dyOptions(stackedGraph = TRUE) %>%
#   dyRangeSelector(height = 20)


```


